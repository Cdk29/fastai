---
title: "Optimizer"
output:
  rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Optimizer}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,eval = FALSE)
```

## Intro

The [fastai](https://github.com/fastai/fastai) library simplifies training fast and accurate neural nets using modern best practices. See the fastai website to get started. The library is based on research into deep learning best practices undertaken at ```fast.ai```, and includes "out of the box" support for ```vision```, ```text```, ```tabular```, and ```collab``` (collaborative filtering) models. 

Interesting posts about NN from scratch using R:

- [Part 1](https://rviews.rstudio.com/2020/07/20/shallow-neural-net-from-scratch-using-r-part-1/)
- [Part 2](https://rviews.rstudio.com/2020/07/24/building-a-neural-net-from-scratch-using-r-part-2/)

## Basic steppers

To be able to give examples of optimizer steps, we will need some steppers, like the following:

```{r}
library(magrittr)
library(fastai)

tst_param = function(val, grad = NULL) {
  "Create a tensor with `val` and a gradient of `grad` for testing"
  res = tensor(val) %>% float()

  if(is.null(grad)) {
    grad = tensor(val / 10)
  } else {
    grad = tensor(grad)
  }

  res$grad = grad %>% float()
  res
}
```

```{r}
p = tst_param(1., 0.1)
p
```

```
tensor(1.)
```

```{r}
sgd_step(p, 1.)
p
```

```
tensor(0.9000)
```

```{r}
p$grad
```

```
tensor(0.1000)
```


## Weight decay

```{r}
p = tst_param(1., 0.1)
weight_decay(p, 1., 0.1)
p
```

```
tensor(0.9000)
```

## L2 regularization

```{r}
p = tst_param(1., 0.1)
l2_reg(p, 1., 0.1)
p$grad
```

```
tensor(0.2000)
```

## Making the step

This method will loop over all param groups, then all parameters for which ```grad``` is not ```NULL``` and call each function in ```stepper```, passing it the parameter p with the hyper-parameters in the corresponding dict in ```hypers```.

```{r}
params = L(lapply(0:3, function(x) tst_param(x)))

opt = Optimizer(params, sgd_step, lr=0.1)

opt$step()

str(params$items)
```

```
List of 4
 $ :tensor(0.)
 $ :tensor(0.9900)
 $ :tensor(1.9800)
 $ :tensor(2.9700)
```

```{r}
params = L(lapply(0:3, function(x) tst_param(x)))

opt = Optimizer(params, list(weight_decay, sgd_step), lr=0.1, wd = 0.1)

opt$step()

str(params$items)
```

```
List of 4
 $ :tensor(0.)
 $ :tensor(0.9800)
 $ :tensor(1.9600)
 $ :tensor(2.9400)
```




